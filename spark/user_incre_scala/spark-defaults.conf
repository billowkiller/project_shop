# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.
# See: http://spark.apache.org/docs/latest/configuration.html
# See: http://wiki.baidu.com/display/SPRK/Spark+Advance+Configuration
# See: http://wiki.baidu.com/display/SPRK/Spark+Configuration

spark.eventLog.enabled true
spark.eventLog.dir hdfs://nmg01-mulan-hdfs.dmop.baidu.com:54310/app/dc/spark/wutao/
spark.yarn.historyServer.address nmg01-mulan-hdfs.dmop.baidu.com:8888
spark.executor.instances 20
spark.executor.cores 8
spark.executor.memory 24G
spark.broadcast.factory org.apache.spark.broadcast.HttpBroadcastFactory

## modify carefully ##
spark.driver.memory 2G
spark.driver.extraJavaOptions -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=4 -XX:NewRatio=3 -XX:SurvivorRatio
=3

spark.executor.extraJavaOptions -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=4 -XX:NewRatio=3 -XX:SurvivorRat
io=3 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationSt
oppedTime
#spark.executor.extraLibraryPath /home/spark/spark-1.2.0.5-baidu-SNAPSHOT-bin-1.3.0/native_lib/

spark.storage.blockManagerSlaveTimeoutMs 240000
spark.storage.memoryFraction 0.2

#spark.shuffle.manager SORT
#spark.shuffle.consolidateFiles true
#
#spark.akka.askTimeout 120
#spark.akka.lookupTimeout 120
spark.akka.frameSize 512
#
spark.io.compression.codec org.apache.spark.io.LZ4CompressionCodec
spark.ui.port 8088
spark.yarn.stage.dir /app/dc/spark/wutao/

# for test, speedup
spark.yarn.maxAppAttempts 1
